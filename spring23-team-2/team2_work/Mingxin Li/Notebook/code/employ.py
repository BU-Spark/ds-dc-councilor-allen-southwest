# -*- coding: utf-8 -*-
"""sex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AU5zbMO9nvXq639Hwh-RsNffTowP-LiZ
"""

!pip install -U -q PyDrive

from pydrive.auth import GoogleAuth

from pydrive.drive import GoogleDrive

from google.colab import auth

from oauth2client.client import GoogleCredentials

  # Authenticate and create the PyDrive client.

auth.authenticate_user()

gauth = GoogleAuth()

gauth.credentials = GoogleCredentials.get_application_default()

drive = GoogleDrive(gauth)

link ='https://drive.google.com/file/d/1ZRpIhr41GN8LDe4rcNQNw-DZlRwby-tn/view?usp=share_link'
import pandas as pd

 # to get the id part of the file

id = link.split("/")[-2]

downloaded = drive.CreateFile({'id':id})

downloaded.GetContentFile('EMPLOYMENT STATUS ACSST5Y2021.S2301-2023-04-03T181932.csv') 

df2021 = pd.read_csv('EMPLOYMENT STATUS ACSST5Y2021.S2301-2023-04-03T181932.csv')

# Remove all columns containing "Margin" in the column name
df2021 = df2021.loc[:, ~df2021.columns.str.contains('Margin')]

# Save the modified DataFrame to a new CSV file
df2021.to_csv('employ 2021 new_file.csv', index=False)

link ='https://drive.google.com/file/d/15NEwfdAM5Br2-4MlGU7wrCCiveuEra8g/view?usp=share_link'
import pandas as pd

 # to get the id part of the file

id = link.split("/")[-2]

downloaded = drive.CreateFile({'id':id})

downloaded.GetContentFile('EMPLOYMENT STATUS ACSST5Y2020.S2301-2023-04-03T181935.csv') 

df2020 = pd.read_csv('EMPLOYMENT STATUS ACSST5Y2020.S2301-2023-04-03T181935.csv')

# Remove all columns containing "Margin" in the column name
df2020 = df2020.loc[:, ~df2020.columns.str.contains('Margin')]

# Save the modified DataFrame to a new CSV file
df2020.to_csv('employ 2020 new_file.csv', index=False)

link ='https://drive.google.com/file/d/1y8gDF0uabEoMaylD3gNOXL_kWPma6uTM/view?usp=share_link'
import pandas as pd

 # to get the id part of the file

id = link.split("/")[-2]

downloaded = drive.CreateFile({'id':id})

downloaded.GetContentFile('EMPLOYMENT STATUS ACSST5Y2019.S2301-2023-04-03T181938.csv') 

df2019 = pd.read_csv('EMPLOYMENT STATUS ACSST5Y2019.S2301-2023-04-03T181938.csv')

# Remove all columns containing "Margin" in the column name
df2019 = df2019.loc[:, ~df2019.columns.str.contains('Margin')]

# Save the modified DataFrame to a new CSV file
df2019.to_csv('employ 2019 new_file.csv', index=False)

link ='https://drive.google.com/file/d/1WteZ6jEBu2D9WI-drcHUfBgiTepH1xi3/view?usp=share_link'
import pandas as pd

 # to get the id part of the file

id = link.split("/")[-2]

downloaded = drive.CreateFile({'id':id})

downloaded.GetContentFile('EMPLOYMENT STATUS ACSST5Y2018.S2301-2023-04-03T181952.csv') 

df2018 = pd.read_csv('EMPLOYMENT STATUS ACSST5Y2018.S2301-2023-04-03T181952.csv')

# Remove all columns containing "Margin" in the column name
df2018 = df2018.loc[:, ~df2018.columns.str.contains('Margin')]

# Save the modified DataFrame to a new CSV file
df2018.to_csv('employ 2018 new_file.csv', index=False)

link ='https://drive.google.com/file/d/1SciqMjmaFVY1WmfIpPttp7LnL9hm0Hfr/view?usp=share_link'
import pandas as pd

 # to get the id part of the file

id = link.split("/")[-2]

downloaded = drive.CreateFile({'id':id})

downloaded.GetContentFile('EMPLOYMENT STATUS ACSST5Y2017.S2301-2023-04-03T181954.csv') 

df2017 = pd.read_csv('EMPLOYMENT STATUS ACSST5Y2017.S2301-2023-04-03T181954.csv')

# Remove all columns containing "Margin" in the column name
df2017 = df2017.loc[:, ~df2017.columns.str.contains('Margin')]

# Save the modified DataFrame to a new CSV file
df2017.to_csv('employ 2017 new_file.csv', index=False)

employ_2021_df = pd.read_csv("employ 2021 new_file.csv")
employ_2020_df = pd.read_csv("employ 2020 new_file.csv")
employ_2019_df = pd.read_csv("employ 2019 new_file.csv")
employ_2018_df = pd.read_csv("employ 2018 new_file.csv")
employ_2017_df = pd.read_csv("employ 2017 new_file.csv")

employ_105_col = 'Census Tract 105, District of Columbia, District of Columbia!!Employment/Population Ratio!!Estimate'
total_105_col = 'Census Tract 105, District of Columbia, District of Columbia!!Total!!Estimate'
unemploy_105_col = 'Census Tract 105, District of Columbia, District of Columbia!!Unemployment rate!!Estimate'

df2021_105_df = df2021[[total_105_col, employ_105_col, unemploy_105_col]].iloc[13:22 , :]
df2021_105_df[employ_105_col]=df2021_105_df[employ_105_col].replace(regex=[r'\D+'], value="")
df2021_105_df[total_105_col]=df2021_105_df[total_105_col].replace(regex=[r'\D+'], value="")
df2021_105_df[unemploy_105_col]=df2021_105_df[unemploy_105_col].replace(regex=[r'\D+'], value="")
#2021
df2021_105_df = df2021_105_df.dropna(subset=[total_105_col, employ_105_col, unemploy_105_col])
df2021_105_df[total_105_col] = df2021_105_df[total_105_col].astype(int)

df2020_105_df = df2020[[total_105_col, employ_105_col, unemploy_105_col]].iloc[13:22 , :]
df2020_105_df[employ_105_col]=df2020_105_df[employ_105_col].replace(regex=[r'\D+'], value="")
df2020_105_df[total_105_col]=df2020_105_df[total_105_col].replace(regex=[r'\D+'], value="")
df2020_105_df[unemploy_105_col]=df2020_105_df[unemploy_105_col].replace(regex=[r'\D+'], value="")
#2020
df2020_105_df = df2020_105_df.dropna(subset=[total_105_col, employ_105_col, unemploy_105_col])
df2020_105_df[total_105_col] = df2020_105_df[total_105_col].astype(int)

df2019_105_df = df2019[[total_105_col, employ_105_col, unemploy_105_col]].iloc[13:22 , :]
df2019_105_df[employ_105_col]=df2019_105_df[employ_105_col].replace(regex=[r'\D+'], value="")
df2019_105_df[total_105_col]=df2019_105_df[total_105_col].replace(regex=[r'\D+'], value="")
df2019_105_df[unemploy_105_col]=df2019_105_df[unemploy_105_col].replace(regex=[r'\D+'], value="")
#2019
df2019_105_df = df2019_105_df.dropna(subset=[total_105_col, employ_105_col, unemploy_105_col])
df2019_105_df[total_105_col] = df2019_105_df[total_105_col].astype(int)

df2018_105_df = df2018[[total_105_col, employ_105_col, unemploy_105_col]].iloc[13:22 , :]
df2018_105_df[employ_105_col]=df2018_105_df[employ_105_col].replace(regex=[r'\D+'], value="")
df2018_105_df[total_105_col]=df2018_105_df[total_105_col].replace(regex=[r'\D+'], value="")
df2018_105_df[unemploy_105_col]=df2018_105_df[unemploy_105_col].replace(regex=[r'\D+'], value="")
#2018
df2018_105_df = df2018_105_df.dropna(subset=[total_105_col, employ_105_col, unemploy_105_col])
df2018_105_df[total_105_col] = df2018_105_df[total_105_col].astype(int)

df2017_105_df = df2017[[total_105_col, employ_105_col, unemploy_105_col]].iloc[13:22 , :]
df2017_105_df[employ_105_col]=df2017_105_df[employ_105_col].replace(regex=[r'\D+'], value="")
df2017_105_df[total_105_col]=df2017_105_df[total_105_col].replace(regex=[r'\D+'], value="")
df2017_105_df[unemploy_105_col]=df2017_105_df[unemploy_105_col].replace(regex=[r'\D+'], value="")
#2017
df2017_105_df = df2017_105_df.dropna(subset=[total_105_col, employ_105_col, unemploy_105_col])
df2017_105_df[total_105_col] = df2017_105_df[total_105_col].astype(int)

import numpy as np
import pandas as pd

# Replace empty string with NaN values
df2017_105_df[employ_105_col] = df2017_105_df[employ_105_col].replace('', float(0))

# Convert column to integer type
df2017_105_df[employ_105_col] = df2017_105_df[employ_105_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2017_105_df[unemploy_105_col] = df2017_105_df[unemploy_105_col].replace('', float(0))

# Convert column to integer type
df2017_105_df[unemploy_105_col] = df2017_105_df[unemploy_105_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2018_105_df[employ_105_col] = df2018_105_df[employ_105_col].replace('', float(0))

# Convert column to integer type
df2018_105_df[employ_105_col] = df2018_105_df[employ_105_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2018_105_df[unemploy_105_col] = df2018_105_df[unemploy_105_col].replace('', float(0))

# Convert column to integer type
df2018_105_df[unemploy_105_col] = df2018_105_df[unemploy_105_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2019_105_df[employ_105_col] = df2019_105_df[employ_105_col].replace('', float(0))

# Convert column to integer type
df2019_105_df[employ_105_col] = df2019_105_df[employ_105_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2019_105_df[unemploy_105_col] = df2019_105_df[unemploy_105_col].replace('', float(0))

# Convert column to integer type
df2019_105_df[unemploy_105_col] = df2019_105_df[unemploy_105_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2020_105_df[employ_105_col] = df2020_105_df[employ_105_col].replace('', float(0))

# Convert column to integer type
df2020_105_df[employ_105_col] = df2020_105_df[employ_105_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2020_105_df[unemploy_105_col] = df2020_105_df[unemploy_105_col].replace('', float(0))

# Convert column to integer type
df2020_105_df[unemploy_105_col] = df2020_105_df[unemploy_105_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2021_105_df[employ_105_col] = df2021_105_df[employ_105_col].replace('', float(0))

# Convert column to integer type
df2021_105_df[employ_105_col] = df2021_105_df[employ_105_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2021_105_df[unemploy_105_col] = df2021_105_df[unemploy_105_col].replace('', float(0))

# Convert column to integer type
df2021_105_df[unemploy_105_col] = df2021_105_df[unemploy_105_col].astype(float).astype(pd.Int64Dtype())

df2017_105_list = df2017_105_df.values.tolist()
df2018_105_list = df2018_105_df.values.tolist()
df2019_105_list = df2019_105_df.values.tolist()
df2020_105_list = df2020_105_df.values.tolist()
df2021_105_list = df2021_105_df.values.tolist()

print(df2017_105_list)

df2017_105_df.head(12)

import matplotlib.pyplot as plt

# Create data
years = [2017, 2018, 2019, 2020 , 2021]

white = []
white.append(int(int(df2017_105_list[0][0]) * int(df2017_105_list[0][1])/1000)) 

white.append(int(int(df2018_105_list[0][0]) * int(df2018_105_list[0][1])/1000)) 

white.append(int(int(df2019_105_list[0][0]) * int(df2019_105_list[0][1])/1000)) 

white.append(int(int(df2020_105_list[0][0]) * int(df2020_105_list[0][1])/1000)) 

white.append(int(int(df2021_105_list[0][0]) * int(df2021_105_list[0][1])/1000)) 

black = []

black.append(int(int(df2017_105_list[1][0]) * int(df2017_105_list[1][1])/1000)) 

black.append(int(int(df2018_105_list[1][0]) * int(df2018_105_list[1][1])/1000)) 

black.append(int(int(df2019_105_list[1][0]) * int(df2019_105_list[1][1])/1000)) 

black.append(int(int(df2020_105_list[1][0]) * int(df2020_105_list[1][1])/1000)) 

black.append(int(int(df2021_105_list[1][0]) * int(df2021_105_list[1][1])/1000)) 
#= [df5_64_list[0][0],df4_64_list[0][0],df3_64_list[0][0],df2_64_list[0][0],df1_64_list[0][0]],

indian = []
indian.append(int(int(df2017_105_list[2][0]) * int(df2017_105_list[2][1])/1000)) 

indian.append(int(int(df2018_105_list[2][0]) * int(df2018_105_list[2][1])/1000)) 

indian.append(int(int(df2019_105_list[2][0]) * int(df2019_105_list[2][1])/1000)) 

indian.append(int(int(df2020_105_list[2][0]) * int(df2020_105_list[2][1])/1000)) 

indian.append(int(int(df2021_105_list[2][0]) * int(df2021_105_list[2][1])/1000)) 


asian = []
asian.append(int(int(df2017_105_list[3][0]) * int(df2017_105_list[3][1])/1000)) 

asian.append(int(int(df2018_105_list[3][0]) * int(df2018_105_list[3][1])/1000)) 

asian.append(int(int(df2019_105_list[3][0]) * int(df2019_105_list[3][1])/1000)) 

asian.append(int(int(df2020_105_list[3][0]) * int(df2020_105_list[3][1])/1000)) 

asian.append(int(int(df2021_105_list[3][0]) * int(df2021_105_list[3][1])/1000)) 

hawaiian = []
hawaiian.append(int(int(df2017_105_list[4][0]) * int(df2017_105_list[4][1])/1000)) 

hawaiian.append(int(int(df2018_105_list[4][0]) * int(df2018_105_list[4][1])/1000)) 

hawaiian.append(int(int(df2019_105_list[4][0]) * int(df2019_105_list[4][1])/1000)) 

hawaiian.append(int(int(df2020_105_list[4][0]) * int(df2020_105_list[4][1])/1000)) 

hawaiian.append(int(int(df2021_105_list[4][0]) * int(df2021_105_list[4][1])/1000)) 


otherss = []
otherss.append(int(int(df2017_105_list[5][0]) * int(df2017_105_list[5][1])/1000)) 

otherss.append(int(int(df2018_105_list[5][0]) * int(df2018_105_list[5][1])/1000)) 

otherss.append(int(int(df2019_105_list[5][0]) * int(df2019_105_list[5][1])/1000)) 

otherss.append(int(int(df2020_105_list[5][0]) * int(df2020_105_list[5][1])/1000)) 

otherss.append(int(int(df2021_105_list[5][0]) * int(df2021_105_list[5][1])/1000)) 


twomore = []
twomore.append(int(int(df2017_105_list[6][0]) * int(df2017_105_list[6][1])/1000)) 

twomore.append(int(int(df2018_105_list[6][0]) * int(df2018_105_list[6][1])/1000)) 

twomore.append(int(int(df2019_105_list[6][0]) * int(df2019_105_list[6][1])/1000)) 

twomore.append(int(int(df2020_105_list[6][0]) * int(df2020_105_list[6][1])/1000)) 

twomore.append(int(int(df2021_105_list[6][0]) * int(df2021_105_list[6][1])/1000)) 

latino = []

latino.append(int(int(df2017_105_list[7][0]) * int(df2017_105_list[7][1])/1000)) 

latino.append(int(int(df2018_105_list[7][0]) * int(df2018_105_list[7][1])/1000)) 

latino.append(int(int(df2019_105_list[7][0]) * int(df2019_105_list[7][1])/1000)) 

latino.append(int(int(df2020_105_list[7][0]) * int(df2020_105_list[7][1])/1000)) 

latino.append(int(int(df2021_105_list[7][0]) * int(df2021_105_list[7][1])/1000)) 



race_units = {
   'White':tuple(white),
   'Black or African American': tuple(black),
   'American Indian and Alaska Native' : tuple(indian),
   'Asian' : tuple(asian),
   'Native Hawaiian and Other Pacific Islander' : tuple(hawaiian),
   'Some other race' : tuple(otherss),
   'Two or more races' : tuple(twomore),
   'Hispanic or Latino origin' : tuple(latino),
   }


   # Plot the graph
fig, ax = plt.subplots()
for race, units in race_units.items():
    ax.plot(years, units, label=race)

# Add legends, titles, axis labels, etc.
ax.set_title('Employed Population Comparison by Race, Data from Cencus Tract 105')
ax.set_xlabel('Year')
ax.set_ylabel('Population')

# Adjust the y-axis scale
max_y = max([max(units) for units in race_units.values()])
ax.set_ylim([0, (max_y // 10 + 1) * 10])

# Move the legend outside of the plot area
ax.legend(bbox_to_anchor=(1.04,0.5), loc="center left", borderaxespad=0)

# Show the chart
plt.show()

import matplotlib.pyplot as plt

# Create data
years = [2017, 2018, 2019, 2020 , 2021]

white = []
white.append(int(int(df2017_105_list[0][0]) * int(df2017_105_list[0][2])/1000)) 

white.append(int(int(df2018_105_list[0][0]) * int(df2018_105_list[0][2])/1000)) 

white.append(int(int(df2019_105_list[0][0]) * int(df2019_105_list[0][2])/1000)) 

white.append(int(int(df2020_105_list[0][0]) * int(df2020_105_list[0][2])/1000)) 

white.append(int(int(df2021_105_list[0][0]) * int(df2021_105_list[0][2])/1000)) 

black = []

black.append(int(int(df2017_105_list[1][0]) * int(df2017_105_list[1][2])/1000)) 

black.append(int(int(df2018_105_list[1][0]) * int(df2018_105_list[1][2])/1000)) 

black.append(int(int(df2019_105_list[1][0]) * int(df2019_105_list[1][2])/1000)) 

black.append(int(int(df2020_105_list[1][0]) * int(df2020_105_list[1][2])/1000)) 

black.append(int(int(df2021_105_list[1][0]) * int(df2021_105_list[1][2])/1000)) 
#= [df5_64_list[0][0],df4_64_list[0][0],df3_64_list[0][0],df2_64_list[0][0],df1_64_list[0][0]],

indian = []
indian.append(int(int(df2017_105_list[2][0]) * int(df2017_105_list[2][2])/1000)) 

indian.append(int(int(df2018_105_list[2][0]) * int(df2018_105_list[2][2])/1000)) 

indian.append(int(int(df2019_105_list[2][0]) * int(df2019_105_list[2][2])/1000)) 

indian.append(int(int(df2020_105_list[2][0]) * int(df2020_105_list[2][2])/1000)) 

indian.append(int(int(df2021_105_list[2][0]) * int(df2021_105_list[2][2])/1000)) 


asian = []
asian.append(int(int(df2017_105_list[3][0]) * int(df2017_105_list[3][2])/1000)) 

asian.append(int(int(df2018_105_list[3][0]) * int(df2018_105_list[3][2])/1000)) 

asian.append(int(int(df2019_105_list[3][0]) * int(df2019_105_list[3][2])/1000)) 

asian.append(int(int(df2020_105_list[3][0]) * int(df2020_105_list[3][2])/1000)) 

asian.append(int(int(df2021_105_list[3][0]) * int(df2021_105_list[3][2])/1000)) 

hawaiian = []
hawaiian.append(int(int(df2017_105_list[4][0]) * int(df2017_105_list[4][2])/1000)) 

hawaiian.append(int(int(df2018_105_list[4][0]) * int(df2018_105_list[4][2])/1000)) 

hawaiian.append(int(int(df2019_105_list[4][0]) * int(df2019_105_list[4][2])/1000)) 

hawaiian.append(int(int(df2020_105_list[4][0]) * int(df2020_105_list[4][2])/1000)) 

hawaiian.append(int(int(df2021_105_list[4][0]) * int(df2021_105_list[4][2])/1000)) 


otherss = []
otherss.append(int(int(df2017_105_list[5][0]) * int(df2017_105_list[5][2])/1000)) 

otherss.append(int(int(df2018_105_list[5][0]) * int(df2018_105_list[5][2])/1000)) 

otherss.append(int(int(df2019_105_list[5][0]) * int(df2019_105_list[5][2])/1000)) 

otherss.append(int(int(df2020_105_list[5][0]) * int(df2020_105_list[5][2])/1000)) 

otherss.append(int(int(df2021_105_list[5][0]) * int(df2021_105_list[5][2])/1000)) 


twomore = []
twomore.append(int(int(df2017_105_list[6][0]) * int(df2017_105_list[6][2])/1000)) 

twomore.append(int(int(df2018_105_list[6][0]) * int(df2018_105_list[6][2])/1000)) 

twomore.append(int(int(df2019_105_list[6][0]) * int(df2019_105_list[6][2])/1000)) 

twomore.append(int(int(df2020_105_list[6][0]) * int(df2020_105_list[6][2])/1000)) 

twomore.append(int(int(df2021_105_list[6][0]) * int(df2021_105_list[6][2])/1000)) 

latino = []

latino.append(int(int(df2017_105_list[7][0]) * int(df2017_105_list[7][2])/1000)) 

latino.append(int(int(df2018_105_list[7][0]) * int(df2018_105_list[7][2])/1000)) 

latino.append(int(int(df2019_105_list[7][0]) * int(df2019_105_list[7][2])/1000)) 

latino.append(int(int(df2020_105_list[7][0]) * int(df2020_105_list[7][2])/1000)) 

latino.append(int(int(df2021_105_list[7][0]) * int(df2021_105_list[7][2])/1000)) 



race_units = {
   'White':tuple(white),
   'Black or African American': tuple(black),
   'American Indian and Alaska Native' : tuple(indian),
   'Asian' : tuple(asian),
   'Native Hawaiian and Other Pacific Islander' : tuple(hawaiian),
   'Some other race' : tuple(otherss),
   'Two or more races' : tuple(twomore),
   'Hispanic or Latino origin' : tuple(latino),
   }


   # Plot the graph
fig, ax = plt.subplots()
for race, units in race_units.items():
    ax.plot(years, units, label=race)

# Add legends, titles, axis labels, etc.
ax.set_title('Unemployed Population Comparison by Race, Data from Cencus Tract 105')
ax.set_xlabel('Year')
ax.set_ylabel('Population')

# Adjust the y-axis scale
max_y = max([max(units) for units in race_units.values()])
ax.set_ylim([0, (max_y // 10 + 1) * 10])

# Move the legend outside of the plot area
ax.legend(bbox_to_anchor=(1.04,0.5), loc="center left", borderaxespad=0)

# Show the chart
plt.show()

employ_64_col = 'Census Tract 64, District of Columbia, District of Columbia!!Employment/Population Ratio!!Estimate'
total_64_col = 'Census Tract 64, District of Columbia, District of Columbia!!Total!!Estimate'
unemploy_64_col = 'Census Tract 64, District of Columbia, District of Columbia!!Unemployment rate!!Estimate'

df2021_64_df = df2021[[total_64_col, employ_64_col, unemploy_64_col]].iloc[13:22 , :]
df2021_64_df[employ_64_col]=df2021_64_df[employ_64_col].replace(regex=[r'\D+'], value="")
df2021_64_df[total_64_col]=df2021_64_df[total_64_col].replace(regex=[r'\D+'], value="")
df2021_64_df[unemploy_64_col]=df2021_64_df[unemploy_64_col].replace(regex=[r'\D+'], value="")
#2021
df2021_64_df = df2021_64_df.dropna(subset=[total_64_col, employ_64_col, unemploy_64_col])
df2021_64_df[total_64_col] = df2021_64_df[total_64_col].astype(int)

df2020_64_df = df2020[[total_64_col, employ_64_col, unemploy_64_col]].iloc[13:22 , :]
df2020_64_df[employ_64_col]=df2020_64_df[employ_64_col].replace(regex=[r'\D+'], value="")
df2020_64_df[total_64_col]=df2020_64_df[total_64_col].replace(regex=[r'\D+'], value="")
df2020_64_df[unemploy_64_col]=df2020_64_df[unemploy_64_col].replace(regex=[r'\D+'], value="")
#2020
df2020_64_df = df2020_64_df.dropna(subset=[total_64_col, employ_64_col, unemploy_64_col])
df2020_64_df[total_64_col] = df2020_64_df[total_64_col].astype(int)

df2019_64_df = df2019[[total_64_col, employ_64_col, unemploy_64_col]].iloc[13:22 , :]
df2019_64_df[employ_64_col]=df2019_64_df[employ_64_col].replace(regex=[r'\D+'], value="")
df2019_64_df[total_64_col]=df2019_64_df[total_64_col].replace(regex=[r'\D+'], value="")
df2019_64_df[unemploy_64_col]=df2019_64_df[unemploy_64_col].replace(regex=[r'\D+'], value="")
#2019
df2019_64_df = df2019_64_df.dropna(subset=[total_64_col, employ_64_col, unemploy_64_col])
df2019_64_df[total_64_col] = df2019_64_df[total_64_col].astype(int)

df2018_64_df = df2018[[total_64_col, employ_64_col, unemploy_64_col]].iloc[13:22 , :]
df2018_64_df[employ_64_col]=df2018_64_df[employ_64_col].replace(regex=[r'\D+'], value="")
df2018_64_df[total_64_col]=df2018_64_df[total_64_col].replace(regex=[r'\D+'], value="")
df2018_64_df[unemploy_64_col]=df2018_64_df[unemploy_64_col].replace(regex=[r'\D+'], value="")
#2018
df2018_64_df = df2018_64_df.dropna(subset=[total_64_col, employ_64_col, unemploy_64_col])
df2018_64_df[total_64_col] = df2018_64_df[total_64_col].astype(int)

df2017_64_df = df2017[[total_64_col, employ_64_col, unemploy_64_col]].iloc[13:22 , :]
df2017_64_df[employ_64_col]=df2017_64_df[employ_64_col].replace(regex=[r'\D+'], value="")
df2017_64_df[total_64_col]=df2017_64_df[total_64_col].replace(regex=[r'\D+'], value="")
df2017_64_df[unemploy_64_col]=df2017_64_df[unemploy_64_col].replace(regex=[r'\D+'], value="")
#2017
df2017_64_df = df2017_64_df.dropna(subset=[total_64_col, employ_64_col, unemploy_64_col])
df2017_64_df[total_64_col] = df2017_64_df[total_64_col].astype(int)


import numpy as np
import pandas as pd

# Replace empty string with NaN values
df2017_64_df[employ_64_col] = df2017_64_df[employ_64_col].replace('', float(0))

# Convert column to integer type
df2017_64_df[employ_64_col] = df2017_64_df[employ_64_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2017_64_df[unemploy_64_col] = df2017_64_df[unemploy_64_col].replace('', float(0))

# Convert column to integer type
df2017_64_df[unemploy_64_col] = df2017_64_df[unemploy_64_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2018_64_df[employ_64_col] = df2018_64_df[employ_64_col].replace('', float(0))

# Convert column to integer type
df2018_64_df[employ_64_col] = df2018_64_df[employ_64_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2018_64_df[unemploy_64_col] = df2018_64_df[unemploy_64_col].replace('', float(0))

# Convert column to integer type
df2018_64_df[unemploy_64_col] = df2018_64_df[unemploy_64_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2019_64_df[employ_64_col] = df2019_64_df[employ_64_col].replace('', float(0))

# Convert column to integer type
df2019_64_df[employ_64_col] = df2019_64_df[employ_64_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2019_64_df[unemploy_64_col] = df2019_64_df[unemploy_64_col].replace('', float(0))

# Convert column to integer type
df2019_64_df[unemploy_64_col] = df2019_64_df[unemploy_64_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2020_64_df[employ_64_col] = df2020_64_df[employ_64_col].replace('', float(0))

# Convert column to integer type
df2020_64_df[employ_64_col] = df2020_64_df[employ_64_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2020_64_df[unemploy_64_col] = df2020_64_df[unemploy_64_col].replace('', float(0))

# Convert column to integer type
df2020_64_df[unemploy_64_col] = df2020_64_df[unemploy_64_col].astype(float).astype(pd.Int64Dtype())


# Replace empty string with NaN values
df2021_64_df[employ_64_col] = df2021_64_df[employ_64_col].replace('', float(0))

# Convert column to integer type
df2021_64_df[employ_64_col] = df2021_64_df[employ_64_col].astype(float).astype(pd.Int64Dtype())

# Replace empty string with NaN values
df2021_64_df[unemploy_64_col] = df2021_64_df[unemploy_64_col].replace('', float(0))

# Convert column to integer type
df2021_64_df[unemploy_64_col] = df2021_64_df[unemploy_64_col].astype(float).astype(pd.Int64Dtype())



df2017_64_list = df2017_64_df.values.tolist()
df2018_64_list = df2018_64_df.values.tolist()
df2019_64_list = df2019_64_df.values.tolist()
df2020_64_list = df2020_64_df.values.tolist()
df2021_64_list = df2021_64_df.values.tolist()


import matplotlib.pyplot as plt

# Create data
years = [2017, 2018, 2019, 2020 , 2021]

white = []
white.append(int(int(df2017_64_list[0][0]) * int(df2017_64_list[0][1])/1000)) 

white.append(int(int(df2018_64_list[0][0]) * int(df2018_64_list[0][1])/1000)) 

white.append(int(int(df2019_64_list[0][0]) * int(df2019_64_list[0][1])/1000)) 

white.append(int(int(df2020_64_list[0][0]) * int(df2020_64_list[0][1])/1000)) 

white.append(int(int(df2021_64_list[0][0]) * int(df2021_64_list[0][1])/1000)) 

black = []

black.append(int(int(df2017_64_list[1][0]) * int(df2017_64_list[1][1])/1000)) 

black.append(int(int(df2018_64_list[1][0]) * int(df2018_64_list[1][1])/1000)) 

black.append(int(int(df2019_64_list[1][0]) * int(df2019_64_list[1][1])/1000)) 

black.append(int(int(df2020_64_list[1][0]) * int(df2020_64_list[1][1])/1000)) 

black.append(int(int(df2021_64_list[1][0]) * int(df2021_64_list[1][1])/1000)) 
#= [df5_64_list[0][0],df4_64_list[0][0],df3_64_list[0][0],df2_64_list[0][0],df1_64_list[0][0]],

indian = []
indian.append(int(int(df2017_64_list[2][0]) * int(df2017_64_list[2][1])/1000)) 

indian.append(int(int(df2018_64_list[2][0]) * int(df2018_64_list[2][1])/1000)) 

indian.append(int(int(df2019_64_list[2][0]) * int(df2019_64_list[2][1])/1000)) 

indian.append(int(int(df2020_64_list[2][0]) * int(df2020_64_list[2][1])/1000)) 

indian.append(int(int(df2021_64_list[2][0]) * int(df2021_64_list[2][1])/1000)) 


asian = []
asian.append(int(int(df2017_64_list[3][0]) * int(df2017_64_list[3][1])/1000)) 

asian.append(int(int(df2018_64_list[3][0]) * int(df2018_64_list[3][1])/1000)) 

asian.append(int(int(df2019_64_list[3][0]) * int(df2019_64_list[3][1])/1000)) 

asian.append(int(int(df2020_64_list[3][0]) * int(df2020_64_list[3][1])/1000)) 

asian.append(int(int(df2021_64_list[3][0]) * int(df2021_64_list[3][1])/1000)) 

hawaiian = []
hawaiian.append(int(int(df2017_64_list[4][0]) * int(df2017_64_list[4][1])/1000)) 

hawaiian.append(int(int(df2018_64_list[4][0]) * int(df2018_64_list[4][1])/1000)) 

hawaiian.append(int(int(df2019_64_list[4][0]) * int(df2019_64_list[4][1])/1000)) 

hawaiian.append(int(int(df2020_64_list[4][0]) * int(df2020_64_list[4][1])/1000)) 

hawaiian.append(int(int(df2021_64_list[4][0]) * int(df2021_64_list[4][1])/1000)) 


otherss = []
otherss.append(int(int(df2017_64_list[5][0]) * int(df2017_64_list[5][1])/1000)) 

otherss.append(int(int(df2018_64_list[5][0]) * int(df2018_64_list[5][1])/1000)) 

otherss.append(int(int(df2019_64_list[5][0]) * int(df2019_64_list[5][1])/1000)) 

otherss.append(int(int(df2020_64_list[5][0]) * int(df2020_64_list[5][1])/1000)) 

otherss.append(int(int(df2021_64_list[5][0]) * int(df2021_64_list[5][1])/1000)) 


twomore = []
twomore.append(int(int(df2017_64_list[6][0]) * int(df2017_64_list[6][1])/1000)) 

twomore.append(int(int(df2018_64_list[6][0]) * int(df2018_64_list[6][1])/1000)) 

twomore.append(int(int(df2019_64_list[6][0]) * int(df2019_64_list[6][1])/1000)) 

twomore.append(int(int(df2020_64_list[6][0]) * int(df2020_64_list[6][1])/1000)) 

twomore.append(int(int(df2021_64_list[6][0]) * int(df2021_64_list[6][1])/1000)) 

latino = []

latino.append(int(int(df2017_64_list[7][0]) * int(df2017_64_list[7][1])/1000)) 

latino.append(int(int(df2018_64_list[7][0]) * int(df2018_64_list[7][1])/1000)) 

latino.append(int(int(df2019_64_list[7][0]) * int(df2019_64_list[7][1])/1000)) 

latino.append(int(int(df2020_64_list[7][0]) * int(df2020_64_list[7][1])/1000)) 

latino.append(int(int(df2021_64_list[7][0]) * int(df2021_64_list[7][1])/1000)) 



race_units = {
   'White':tuple(white),
   'Black or African American': tuple(black),
   'American Indian and Alaska Native' : tuple(indian),
   'Asian' : tuple(asian),
   'Native Hawaiian and Other Pacific Islander' : tuple(hawaiian),
   'Some other race' : tuple(otherss),
   'Two or more races' : tuple(twomore),
   'Hispanic or Latino origin' : tuple(latino),
   }


   # Plot the graph
fig, ax = plt.subplots()
for race, units in race_units.items():
    ax.plot(years, units, label=race)

# Add legends, titles, axis labels, etc.
ax.set_title('Employed Population Comparison by Race, Data from Cencus Tract 64')
ax.set_xlabel('Year')
ax.set_ylabel('Population')

# Adjust the y-axis scale
max_y = max([max(units) for units in race_units.values()])
ax.set_ylim([0, (max_y // 10 + 1) * 10])

# Move the legend outside of the plot area
ax.legend(bbox_to_anchor=(1.04,0.5), loc="center left", borderaxespad=0)

# Show the chart
plt.show()

import matplotlib.pyplot as plt

# Create data
years = [2017, 2018, 2019, 2020 , 2021]

white = []
white.append(int(int(df2017_64_list[0][0]) * int(df2017_64_list[0][2])/1000)) 

white.append(int(int(df2018_64_list[0][0]) * int(df2018_64_list[0][2])/1000)) 

white.append(int(int(df2019_64_list[0][0]) * int(df2019_64_list[0][2])/1000)) 

white.append(int(int(df2020_64_list[0][0]) * int(df2020_64_list[0][2])/1000)) 

white.append(int(int(df2021_64_list[0][0]) * int(df2021_64_list[0][2])/1000)) 

black = []

black.append(int(int(df2017_64_list[1][0]) * int(df2017_64_list[1][2])/1000)) 

black.append(int(int(df2018_64_list[1][0]) * int(df2018_64_list[1][2])/1000)) 

black.append(int(int(df2019_64_list[1][0]) * int(df2019_64_list[1][2])/1000)) 

black.append(int(int(df2020_64_list[1][0]) * int(df2020_64_list[1][2])/1000)) 

black.append(int(int(df2021_64_list[1][0]) * int(df2021_64_list[1][2])/1000)) 
#= [df5_64_list[0][0],df4_64_list[0][0],df3_64_list[0][0],df2_64_list[0][0],df1_64_list[0][0]],

indian = []
indian.append(int(int(df2017_64_list[2][0]) * int(df2017_64_list[2][2])/1000)) 

indian.append(int(int(df2018_64_list[2][0]) * int(df2018_64_list[2][2])/1000)) 

indian.append(int(int(df2019_64_list[2][0]) * int(df2019_64_list[2][2])/1000)) 

indian.append(int(int(df2020_64_list[2][0]) * int(df2020_64_list[2][2])/1000)) 

indian.append(int(int(df2021_64_list[2][0]) * int(df2021_64_list[2][2])/1000)) 


asian = []
asian.append(int(int(df2017_64_list[3][0]) * int(df2017_64_list[3][2])/1000)) 

asian.append(int(int(df2018_64_list[3][0]) * int(df2018_64_list[3][2])/1000)) 

asian.append(int(int(df2019_64_list[3][0]) * int(df2019_64_list[3][2])/1000)) 

asian.append(int(int(df2020_64_list[3][0]) * int(df2020_64_list[3][2])/1000)) 

asian.append(int(int(df2021_64_list[3][0]) * int(df2021_64_list[3][2])/1000)) 

hawaiian = []
hawaiian.append(int(int(df2017_64_list[4][0]) * int(df2017_64_list[4][2])/1000)) 

hawaiian.append(int(int(df2018_64_list[4][0]) * int(df2018_64_list[4][2])/1000)) 

hawaiian.append(int(int(df2019_64_list[4][0]) * int(df2019_64_list[4][2])/1000)) 

hawaiian.append(int(int(df2020_64_list[4][0]) * int(df2020_64_list[4][2])/1000)) 

hawaiian.append(int(int(df2021_64_list[4][0]) * int(df2021_64_list[4][2])/1000)) 


otherss = []
otherss.append(int(int(df2017_64_list[5][0]) * int(df2017_64_list[5][2])/1000)) 

otherss.append(int(int(df2018_64_list[5][0]) * int(df2018_64_list[5][2])/1000)) 

otherss.append(int(int(df2019_64_list[5][0]) * int(df2019_64_list[5][2])/1000)) 

otherss.append(int(int(df2020_64_list[5][0]) * int(df2020_64_list[5][2])/1000)) 

otherss.append(int(int(df2021_64_list[5][0]) * int(df2021_64_list[5][2])/1000)) 


twomore = []
twomore.append(int(int(df2017_64_list[6][0]) * int(df2017_64_list[6][2])/1000)) 

twomore.append(int(int(df2018_64_list[6][0]) * int(df2018_64_list[6][2])/1000)) 

twomore.append(int(int(df2019_64_list[6][0]) * int(df2019_64_list[6][2])/1000)) 

twomore.append(int(int(df2020_64_list[6][0]) * int(df2020_64_list[6][2])/1000)) 

twomore.append(int(int(df2021_64_list[6][0]) * int(df2021_64_list[6][2])/1000)) 

latino = []

latino.append(int(int(df2017_64_list[7][0]) * int(df2017_64_list[7][2])/1000)) 

latino.append(int(int(df2018_64_list[7][0]) * int(df2018_64_list[7][2])/1000)) 

latino.append(int(int(df2019_64_list[7][0]) * int(df2019_64_list[7][2])/1000)) 

latino.append(int(int(df2020_64_list[7][0]) * int(df2020_64_list[7][2])/1000)) 

latino.append(int(int(df2021_64_list[7][0]) * int(df2021_64_list[7][2])/1000)) 



race_units = {
   'White':tuple(white),
   'Black or African American': tuple(black),
   'American Indian and Alaska Native' : tuple(indian),
   'Asian' : tuple(asian),
   'Native Hawaiian and Other Pacific Islander' : tuple(hawaiian),
   'Some other race' : tuple(otherss),
   'Two or more races' : tuple(twomore),
   'Hispanic or Latino origin' : tuple(latino),
   }


   # Plot the graph
fig, ax = plt.subplots()
for race, units in race_units.items():
    ax.plot(years, units, label=race)

# Add legends, titles, axis labels, etc.
ax.set_title('Unemployed Population Comparison by Race, Data from Cencus Tract 64')
ax.set_xlabel('Year')
ax.set_ylabel('Population')

# Adjust the y-axis scale
max_y = max([max(units) for units in race_units.values()])
ax.set_ylim([0, (max_y // 10 + 1) * 10])

# Move the legend outside of the plot area
ax.legend(bbox_to_anchor=(1.04,0.5), loc="center left", borderaxespad=0)

# Show the chart
plt.show()